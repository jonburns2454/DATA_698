{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b055e19b",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'scaler' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 201\u001b[0m\n\u001b[0;32m    198\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m    200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 201\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 118\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;66;03m# Prepare LSTM data\u001b[39;00m\n\u001b[0;32m    117\u001b[0m n_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m  \u001b[38;5;66;03m# Number of time steps to look back\u001b[39;00m\n\u001b[1;32m--> 118\u001b[0m X_train, y_train, scaler \u001b[38;5;241m=\u001b[39m \u001b[43mprepare_lstm_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    119\u001b[0m X_test, y_test, _ \u001b[38;5;241m=\u001b[39m prepare_lstm_data(test, n_steps)\n\u001b[0;32m    121\u001b[0m \u001b[38;5;66;03m# Build and train model\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[1], line 92\u001b[0m, in \u001b[0;36mprepare_lstm_data\u001b[1;34m(df, n_steps)\u001b[0m\n\u001b[0;32m     89\u001b[0m         X\u001b[38;5;241m.\u001b[39mappend(scaled_features[i\u001b[38;5;241m-\u001b[39mn_steps:i])\n\u001b[0;32m     90\u001b[0m         y\u001b[38;5;241m.\u001b[39mappend(target[i])\n\u001b[1;32m---> 92\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(X), np\u001b[38;5;241m.\u001b[39marray(y), \u001b[43mscaler\u001b[49m\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: cannot access local variable 'scaler' where it is not associated with a value"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras impor\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load and preprocess data\n",
    "def load_and_preprocess_data(filepath):\n",
    "    df = pd.read_csv(filepath)\n",
    "    \n",
    "    # Filter relevant columns and drop rows with missing target\n",
    "    df = df.dropna(subset=['percent_food_insecure'])\n",
    "    \n",
    "    # Convert rural_urban to numeric\n",
    "    df['rural_urban'] = pd.factorize(df['rural_urban'])[0]\n",
    "    \n",
    "    # Create lag features\n",
    "    df = df.sort_values(['fips', 'year'])\n",
    "    df['food_insecure_lag1'] = df.groupby('fips')['percent_food_insecure'].shift(1)\n",
    "    df['food_insecure_lag2'] = df.groupby('fips')['percent_food_insecure'].shift(2)\n",
    "    \n",
    "    # Drop rows with missing lag features\n",
    "    df = df.dropna(subset=['food_insecure_lag1', 'food_insecure_lag2'])\n",
    "    \n",
    "    # Select features - adjust as needed\n",
    "    features = [\n",
    "        'percent_household_income_required_for_child_care_expenses',\n",
    "        'food_environment_index',\n",
    "        'percent_fair_or_poor_health',\n",
    "        'percent_unemployed',\n",
    "        'percent_children_in_poverty',\n",
    "        'percent_severe_housing_problems',\n",
    "        'percent_completed_high_school',\n",
    "        'percent_frequent_mental_distress',\n",
    "        'percent_uninsured_children',\n",
    "        'percent_disconnected_youth',\n",
    "        'spending_per_pupil',\n",
    "        'school_funding_adequacy',\n",
    "        'high_school_graduation_rate',\n",
    "        'median_household_income',\n",
    "        'gender_pay_gap',\n",
    "        'percent_enrolled_in_free_or_reduced_lunch',\n",
    "        'percent_households_with_severe_cost_burden',\n",
    "        'percent_rural',\n",
    "        'percent_65_and_over',\n",
    "        'percent_not_proficient_in_english',\n",
    "        'segregation_index',\n",
    "        'teen_birth_rate',\n",
    "        'percent_children_in_single_parent_households',\n",
    "        'percent_low_birthweight',\n",
    "        'percent_black',\n",
    "        'rural_urban',\n",
    "        'food_insecure_lag1',\n",
    "        'food_insecure_lag2'\n",
    "    ]\n",
    "    \n",
    "    # Filter only available features\n",
    "    available_features = [f for f in features if f in df.columns]\n",
    "    df = df[['year', 'fips', 'county.x', 'state.x', 'percent_food_insecure'] + available_features]\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Prepare data for LSTM\n",
    "def prepare_lstm_data(df, n_steps=3):\n",
    "    counties = df['fips'].unique()\n",
    "    X, y = [], []\n",
    "    \n",
    "    for county in counties:\n",
    "        county_data = df[df['fips'] == county].sort_values('year')\n",
    "        \n",
    "        # Skip counties with insufficient data\n",
    "        if len(county_data) < n_steps:\n",
    "            continue\n",
    "            \n",
    "        # Get features and target\n",
    "        features = county_data.drop(columns=['year', 'fips', 'county.x', 'state.x', 'percent_food_insecure'])\n",
    "        target = county_data['percent_food_insecure'].values\n",
    "        \n",
    "        # Normalize features\n",
    "        scaler = MinMaxScaler()\n",
    "        scaled_features = scaler.fit_transform(features)\n",
    "        \n",
    "        # Create sequences\n",
    "        for i in range(n_steps, len(county_data)):\n",
    "            X.append(scaled_features[i-n_steps:i])\n",
    "            y.append(target[i])\n",
    "    \n",
    "    return np.array(X), np.array(y), scaler\n",
    "\n",
    "# Build LSTM model\n",
    "def build_lstm_model(input_shape):\n",
    "    model = Sequential([\n",
    "        LSTM(50, activation='relu', input_shape=input_shape, return_sequences=True),\n",
    "        Dropout(0.2),\n",
    "        LSTM(50, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model\n",
    "\n",
    "# Main execution\n",
    "def main():\n",
    "    # Load and preprocess data\n",
    "    df = load_and_preprocess_data('C:\\\\Users\\\\jashb\\\\OneDrive\\\\Documents\\\\Masters Data Science\\\\Spring 2025\\\\DATA 698\\\\Masters Project\\\\final_data.csv')\n",
    "    \n",
    "    # Split into train and test\n",
    "    train = df[df['year'] < 2024]\n",
    "    test = df[df['year'] == 2024]\n",
    "    \n",
    "    # Prepare LSTM data\n",
    "    n_steps = 3  # Number of time steps to look back\n",
    "    X_train, y_train, scaler = prepare_lstm_data(train, n_steps)\n",
    "    X_test, y_test, _ = prepare_lstm_data(test, n_steps)\n",
    "    \n",
    "    # Build and train model\n",
    "    model = build_lstm_model((X_train.shape[1], X_train.shape[2]))\n",
    "    history = model.fit(X_train, y_train, epochs=100, batch_size=32, \n",
    "                       validation_split=0.2, verbose=1)\n",
    "    \n",
    "    # Evaluate model\n",
    "    train_pred = model.predict(X_train)\n",
    "    test_pred = model.predict(X_test)\n",
    "    \n",
    "    print(f\"Train RMSE: {np.sqrt(mean_squared_error(y_train, train_pred))}\")\n",
    "    print(f\"Test RMSE: {np.sqrt(mean_squared_error(y_test, test_pred))}\")\n",
    "    \n",
    "    # Plot training history\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.title('Model Training History')\n",
    "    plt.show()\n",
    "    \n",
    "    # Prepare 2025 predictions\n",
    "    # We'll use 2022-2024 data to predict 2025 for each county\n",
    "    predictions_2025 = []\n",
    "    counties_2025 = []\n",
    "    \n",
    "    for county in df['fips'].unique():\n",
    "        county_data = df[df['fips'] == county].sort_values('year')\n",
    "        \n",
    "        # We need at least n_steps years of data\n",
    "        if len(county_data) < n_steps:\n",
    "            continue\n",
    "            \n",
    "        # Get the most recent n_steps years\n",
    "        recent_data = county_data.tail(n_steps)\n",
    "        \n",
    "        # Prepare features\n",
    "        features = recent_data.drop(columns=['year', 'fips', 'county.x', 'state.x', 'percent_food_insecure'])\n",
    "        scaled_features = scaler.transform(features)\n",
    "        \n",
    "        # Reshape for LSTM\n",
    "        X_county = scaled_features.reshape(1, n_steps, -1)\n",
    "        \n",
    "        # Predict\n",
    "        pred = model.predict(X_county)[0][0]\n",
    "        predictions_2025.append(pred)\n",
    "        counties_2025.append(county)\n",
    "    \n",
    "    # Create results dataframe\n",
    "    results_2025 = pd.DataFrame({\n",
    "        'fips': counties_2025,\n",
    "        'county': [df[df['fips'] == fips]['county.x'].iloc[0] for fips in counties_2025],\n",
    "        'current_food_insecure': [df[(df['fips'] == fips) & (df['year'] == 2024)]['percent_food_insecure'].values[0] \n",
    "                                 for fips in counties_2025],\n",
    "        'pred_2025_food_insecure': predictions_2025\n",
    "    })\n",
    "    \n",
    "    # Calculate predicted change and risk categories\n",
    "    results_2025['predicted_change'] = results_2025['pred_2025_food_insecure'] - results_2025['current_food_insecure']\n",
    "    results_2025['risk_category'] = pd.qcut(results_2025['pred_2025_food_insecure'], \n",
    "                                          q=[0, 0.25, 0.75, 1], \n",
    "                                          labels=['Low Risk', 'Medium Risk', 'High Risk'])\n",
    "    \n",
    "    # Sort by highest predicted food insecurity\n",
    "    results_2025 = results_2025.sort_values('pred_2025_food_insecure', ascending=False)\n",
    "    \n",
    "    # Save results\n",
    "    results_2025.to_csv('food_insecurity_predictions_lstm.csv', index=False)\n",
    "    \n",
    "    # Visualize top 10 high-risk counties\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.bar(results_2025.head(10)['county'], \n",
    "            results_2025.head(10)['pred_2025_food_insecure'], \n",
    "            color='firebrick')\n",
    "    plt.title('Top 10 High-Risk Counties for 2025 Food Insecurity')\n",
    "    plt.xlabel('County')\n",
    "    plt.ylabel('Predicted Food Insecurity Rate')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
