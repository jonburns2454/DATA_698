---
title: "Thesis Project"
author: "Jonathan Burns"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

```

# Packages Used : running list
```{r message=FALSE, warning=FALSE}
library(tidyverse)
library(readxl)
library(janitor)
library(psych)
```


# Data Cleaning {.tabset}

## Specify target columns

```{r}
# Taking out only the targeted variables needed for the analysis as there were much more availible in the health outcomes datasets. 

columns_to_extract <- c("year","fips", "state", "county", "percent_food_insecure","percent_frequent_mental_distress",
                        "percent_uninsured_children", "percent_disconnected_youth", "spending_per_pupil","school_funding_adequacy", "high_school_graduation_rate", "median_household_income", "gender_pay_gap", "percent_enrolled_in_free_or_reduced_lunch", "percent_household_income_required_for_child_care_expenses", "percent_households_with_severe_cost_burden", "percent_rural", "percent_65_and_over", "percent_black","percent_not_proficient_in_english", "segregation_index", "percent_disconnected_youth", "food_environment_index", "teen_birth_rate", "percent_fair_or_poor_health", "percent_unemployed", "percent_children_in_single_parent_households", "percent_children_in_poverty", "percent_severe_housing_problems", "percent_completed_high_school","percent_completed_high_school", "percent_low_birthweight")

```

## Pull in data

```{r}
main_25 <- "https://raw.githubusercontent.com/jonburns2454/DATA_698/refs/heads/main/DATA/main_25.csv"
supp_25 <- "https://raw.githubusercontent.com/jonburns2454/DATA_698/refs/heads/main/DATA/supp_25.csv"
main_24 <- "https://raw.githubusercontent.com/jonburns2454/DATA_698/refs/heads/main/DATA/main_24.csv"
supp_24 <- "https://raw.githubusercontent.com/jonburns2454/DATA_698/refs/heads/main/DATA/supp_24.csv"
main_23 <- "https://raw.githubusercontent.com/jonburns2454/DATA_698/refs/heads/main/DATA/main_23.csv"
supp_23 <- "https://raw.githubusercontent.com/jonburns2454/DATA_698/refs/heads/main/DATA/supp_23.csv"
main_22 <- "https://raw.githubusercontent.com/jonburns2454/DATA_698/refs/heads/main/DATA/main_22.csv"
supp_22 <- "https://raw.githubusercontent.com/jonburns2454/DATA_698/refs/heads/main/DATA/supp_22.csv"
main_21 <- "https://raw.githubusercontent.com/jonburns2454/DATA_698/refs/heads/main/DATA/main_21.csv"
supp_21 <- "https://raw.githubusercontent.com/jonburns2454/DATA_698/refs/heads/main/DATA/supp_21.csv"
main_20 <- "https://raw.githubusercontent.com/jonburns2454/DATA_698/refs/heads/main/DATA/main_20.csv"
supp_20 <- "https://raw.githubusercontent.com/jonburns2454/DATA_698/refs/heads/main/DATA/supp_20.csv"
```


## Ensure naming conventions are all the same

```{r}
clean_and_select <- function(file_path, columns_to_extract) {
  data <- read.csv(file_path, check.names = FALSE) %>%
    janitor::clean_names() %>%
    select(any_of(columns_to_extract))
  return(data)
}
m_25 <- clean_and_select(main_25, columns_to_extract)
s_25 <- clean_and_select(supp_25, columns_to_extract)

m_24 <- clean_and_select(main_24, columns_to_extract)
s_24 <- clean_and_select(supp_24, columns_to_extract)

m_23 <- clean_and_select(main_23, columns_to_extract)
s_23 <- clean_and_select(supp_23, columns_to_extract)

m_22 <- clean_and_select(main_22, columns_to_extract)
s_22 <- clean_and_select(supp_22, columns_to_extract)

m_21 <- clean_and_select(main_21, columns_to_extract)
s_21 <- clean_and_select(supp_21, columns_to_extract)

m_20 <- clean_and_select(main_20, columns_to_extract)
s_20 <- clean_and_select(supp_20, columns_to_extract)

```

## Join in Main and Supplemental Data by Year

```{r}

f_25 <- m_25 %>% 
  left_join(s_25, by = c("year", "fips")) %>% 
  select(-state.y, -county.y)

f_24 <- m_24 %>% 
  left_join(s_24, by = c("year", "fips")) %>% 
  select(-state.y, -county.y)

f_23 <- m_23 %>% 
  left_join(s_23, by = c("year", "fips")) %>% 
  select(-state.y, -county.y)

f_22 <- m_22 %>% 
  left_join(s_22, by = c("year", "fips")) %>% 
  select(-state.y, -county.y)

f_21 <- m_21 %>% 
  left_join(s_21, by = c("year", "fips")) %>% 
  select(-state.y, -county.y)

f_20 <- m_20 %>% 
  left_join(s_20, by = c("year", "fips")) %>% 
  select(-state.y, -county.y)
```

## Bind Yearly Data Together

```{r}
final <- bind_rows(f_25, f_24, f_23, f_22, f_21, f_20)
final_data_clean <- final %>%
  select(where(~ !any(is.na(.))))
```

## Rural | Urban Category Creation

```{r}
final <- final %>%
  mutate(
    rural_urban = case_when(
      percent_rural == 100 ~ "Completely Rural",
      percent_rural >= 50 & percent_rural < 100 ~ "Mostly Rural",
      percent_rural < 50 ~ "Mostly Urban",
      TRUE ~ NA_character_ 
    )
  )
    
```

## Dropping NA Columns vs Imputing

```{r}

total_rows <- nrow(final)


missing_counts <- colSums(is.na(final))

missing_percentage <- (missing_counts / total_rows) * 100


missing_table <- data.frame(
  Column = names(missing_counts),
  MissingCount = missing_counts,
  MissingPercentage = round(missing_percentage, 2) 
)

missing_table <- missing_table[missing_table$MissingCount > 0, ]

print(missing_table)
```

# EDA {.tabset}

## Summary Statistics

```{r}
describe(final, fast = T)
```

## Missingness Visualized

```{r}
ggplot(missing_table, aes(x = reorder(Column, -MissingPercentage), y = MissingPercentage)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  coord_flip() + 
  labs(
    title = "Percentage of Missing Data by Variable",
    x = "Variable",
    y = "Missingness %"
  ) +
  theme_minimal()
```

##Numeric Distribution

* Quick sapply function to look at histogram distributions for all of the numeric variables in the dataset
* The target variable percent_food_insecure is normally distributed

```{r}
library(ggplot2)
numeric_columns <- sapply(final, is.numeric)
final_numeric <- final[, numeric_columns]

for (col in names(final_numeric)) {
  print(
    ggplot(final, aes_string(x = col)) +
      geom_histogram(fill = "steelblue", bins = 30, color = "black") +
      labs(title = paste("Distribution of", col), x = col, y = "Frequency") +
      theme_minimal()
  )
}
```


## By Year:
* Mean, median and standard deviation were calculated for each variable and then grouped by year.

```{r}
library(dplyr)

yearly_summary <- final %>%
  group_by(year) %>%
  summarise(across(where(is.numeric), list(mean = mean, median = median, sd = sd), na.rm = TRUE))

print(yearly_summary)
```

## By County
* Same thing for county level averages, median and sd for each var.

```{r}
region_summary <- final %>%
  group_by(county.x, year) %>%
  summarise(across(where(is.numeric), list(mean = mean, median = median, sd = sd), na.rm = TRUE))

print(region_summary)
```

## Yearly Line Graph of Food Insecurity
* Despite this graph being messy, there is a point to it.
* A trend appears, there is an overall shift down in food insecurity from 2023 -> 2024, followed by a shift upward in 2025, past where is was in the previous 4 years for most counties.
* Additionally, the Bronx is an outlier for food insecurity showing 1. a much higher starting point in 2020, but also the increase over the five years is sharp.

```{r}
library(ggplot2)

ggplot(region_summary, aes(x = year, y = percent_food_insecure_mean, color = county.x)) +
  geom_line() +
  labs(title = "Yearly Food Insecurity Across New York State Counties", x = "Year", y = "Food Insecurity") +
  theme_minimal()
```

## Average trend in food insecurity across NYS only.

```{r}

ggplot(region_summary, aes(x = year, y = percent_food_insecure_mean)) +
  geom_line() +
  labs(title = "Yearly Average Food Insecurity Across New York State", x = "Year", y = "Value") +
  theme_minimal()
```

```{r}

ggplot(final, aes(x = county.x, y = percent_food_insecure, color = rural_urban)) +
  geom_boxplot(fill = "steelblue") +
  labs(title = "County Level Comparison of Food Insecurity In New York State", x = "County", y = "Food Insecurity Percentage") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, size = 7))
```

## Saving out final csv for cross use in my python code (for LSTM) and the xGBoost.

```{r}
final_csv <- write_csv(final, "C:\\Users\\jashb\\OneDrive\\Documents\\Masters Data Science\\Spring 2025\\DATA 698\\Masters Project\\final_data.csv")
```


# Model Testing: {.tabset}

## XGBoost 1: {.tabset}

* This first XGBoost model aims to be a lighter weight model, only selecting 10 variables from the dataset. Additionally, I only created two lag features and recoded my categorical rural_urban column as numeric
```{r}

library(tidyverse)
library(xgboost)
library(caret)

data <- read.csv("C:\\Users\\jashb\\OneDrive\\Documents\\Masters Data Science\\Spring 2025\\DATA 698\\Masters Project\\final_data.csv")

df <- data %>%
  select(year, fips, county.x, percent_food_insecure,
    percent_unemployed, percent_children_in_poverty,
    median_household_income, percent_fair_or_poor_health,
    high_school_graduation_rate, rural_urban
  ) %>%
  drop_na(percent_food_insecure)  #just making sure there are no na's left in for this XGBoost model
```

### Create Lag Features and code rural_urban on
* Using a standard 1 and 2 year lag variable for the entire model

```{r}

df <- df %>%
  arrange(fips, year) %>% 
  group_by(fips) %>%
  mutate(
    food_insecure_lag1 = lag(percent_food_insecure, 1),  # Previous year
    food_insecure_lag2 = lag(percent_food_insecure, 2)   # Two years back
  ) %>%
  ungroup()

# recode rural_urban as numeric
df <- df %>%
  mutate(rural_urban = as.factor(rural_urban),
         rural_urban = as.numeric(rural_urban))
```

### Split Data

```{r}
train <- df %>% filter(year < 2024)
test <- df %>% filter(year == 2024)

# dropping out the non-important features, including the dependent variable
X_train <- train %>% select(-c(year, fips, county.x, percent_food_insecure))
y_train <- train$percent_food_insecure

X_test <- test %>% select(-c(year, fips, county.x, percent_food_insecure))
y_test <- test$percent_food_insecure
```


### Experiment 1: Train Model

```{r}
# cross val
ctrl <- trainControl(
  method = "cv",
  number = 10,
  verboseIter = TRUE
)

# Standard xgboost tuning grid
xgb_grid <- expand.grid(
  nrounds = 100,
  max_depth = 6,
  eta = 0.3,
  gamma = 0,
  colsample_bytree = 1,
  min_child_weight = 1,
  subsample = 1
)


xgb_model <- train(
  x = X_train,
  y = y_train,
  method = "xgbTree",
  trControl = ctrl,
  tuneGrid = xgb_grid,
  verbosity = 0
)


print(xgb_model)
```

### Apply Experiment 1 Model:
```{r}
# predicting 2024 data
X_2024 <- df %>% 
  filter(year == 2024) %>%
  select(-c(year, fips, county.x, percent_food_insecure))

# Predicting 2024 food insecurity
predictions_2024 <- predict(xgb_model, newdata = X_2024)

# bringing in county and fips codes 
results <- df %>%
  filter(year == 2024) %>%
  select(fips, county.x) %>%
  mutate(pred_2024_food_insecure = predictions_2024)

# View predictions
print(results)
```

### Experiment 1: Predicted vs Actual Food Insecurity

```{r}
# Predict 2024 (for validPrediPredir)
pred_2024 <- predict(xgb_model, newdata = X_test)

# Calculate RMSE
rmse <- sqrt(mean((pred_2024 - y_test)^2))
print(paste("RMSE:", rmse))

ggplot(data.frame(Actual = y_test, Predicted = pred_2024), aes(Actual, Predicted)) +
  geom_point() +
  geom_abline(slope = 1, intercept = 0, color = "red") +
  labs(title = "Actual vs. Predicted Food Insecurity (2024)")
```

### Experiment 1 Data Metrics Table
```{r}

library(caret)
library(Metrics)

test_predictions <- predict(xgb_model, newdata = X_test)
actual_values <- y_test 

metrics_table <- data.frame(
  RMSE = RMSE(test_predictions, actual_values),
  MAPE = mape(actual_values, test_predictions) * 100,
  MSE = mean((test_predictions - actual_values)^2),
  R2 = R2(test_predictions, actual_values)
)

print(metrics_table)
```

## XGBoost 2: {.tabset}

* XGBoost model 2 brings in a few different changes to the model, the lag variables are still created but this time the model is tuned to be faster.
* By dropping the number of folds from 10 to 5 this should cut the number of boosted models ran for this experiment.

```{r}
library(tidyverse)
library(xgboost)
library(caret)


data <- read.csv("C:\\Users\\jashb\\OneDrive\\Documents\\Masters Data Science\\Spring 2025\\DATA 698\\Masters Project\\final_data.csv")


df <- data %>%
  select(where(~ all(!is.na(.)))) %>%
  drop_na(percent_food_insecure)
```

```{r}
df <- df %>%
  arrange(fips, year) %>% 
  group_by(fips) %>%
  mutate(
    food_insecure_lag1 = lag(percent_food_insecure, 1),  # Previous year
    food_insecure_lag2 = lag(percent_food_insecure, 2)   # Two years back
  ) %>%
  select(-food_environment_index) %>% 
  ungroup()


df <- df %>%
  mutate(rural_urban = as.factor(rural_urban),
         rural_urban = as.numeric(rural_urban))
```

```{r}
train <- df %>% filter(year < 2024)
test <- df %>% filter(year == 2024)


X_train <- train %>% select(-c(year, fips, county.x, percent_food_insecure, state.x))
y_train <- train$percent_food_insecure

X_test <- test %>% select(-c(year, fips, county.x, percent_food_insecure, state.x))
y_test <- test$percent_food_insecure
```

```{r warning=FALSE}

ctrl_fast <- trainControl(
  method = "cv",
  number = 5,  # Reduced from 10 folds
  verboseIter = TRUE,
  allowParallel = TRUE  # Enable parallel processing
)

# Tuning grid set
xgb_grid_fast <- expand.grid(
  nrounds = c(100, 150, 200, 300),          # Reduced options
  max_depth = c(4, 6, 8),            # Most useful range
  eta = c(0.05, 0.1, .15),            # Optimal learning rates
  gamma = 0,                     
  colsample_bytree = 0.8,       
  min_child_weight = 1,          
  subsample = 0.8               
)

# Parallel processing to speed things up
library(doParallel)
cl <- makePSOCKcluster(4)
registerDoParallel(cl)

xgb_fast <- train(
  x = X_train,
  y = y_train,
  method = "xgbTree",
  trControl = ctrl_fast,
  tuneGrid = xgb_grid_fast,
  verbosity = 0,
  metric = "RMSE"
)

stopCluster(cl)


print(xgb_fast)
plot(xgb_fast)
```


```{r}
library(doParallel)
library(Metrics)
cl <- makePSOCKcluster(4)
registerDoParallel(cl)


ctrl_fast <- trainControl(
  method = "cv",
  number = 5,  # Reduced from 10 folds
  verboseIter = TRUE,
  allowParallel = TRUE,  # Enable parallel processing
  savePredictions = "final"
)

xgb_grid_fast <- expand.grid(
  nrounds = c(100, 150, 200, 300),
  max_depth = c(4, 6, 8),
  eta = c(0.05, 0.1, 0.15),
  gamma = 0,
  colsample_bytree = 0.8,
  min_child_weight = 1,
  subsample = 0.8
)

# Train the  model
xgb_optimized <- train(
  x = X_train,
  y = y_train,
  method = "xgbTree",
  trControl = ctrl_fast,
  tuneGrid = xgb_grid_fast,
  verbosity = 0,
  metric = "RMSE"
)

stopCluster(cl)


print(xgb_optimized)
plot(xgb_optimized)


best_params <- xgb_optimized$bestTune


X_2024 <- df %>% 
  filter(year == 2024) %>%
  select(-c(year, fips, county.x, percent_food_insecure)) %>%
 
  mutate(
    rural_urban = as.numeric(factor(rural_urban))
  )


predictions_2024 <- predict(xgb_optimized, newdata = X_2024)


results_2024 <- df %>%
  filter(year == 2024) %>%
  select(fips, county.x, percent_food_insecure) %>%  
  mutate(
    pred_2024_food_insecure = predictions_2024,
    predicted_change = pred_2024_food_insecure - percent_food_insecure,
    risk_category = case_when(
      pred_2024_food_insecure > quantile(predictions_2024, 0.75) ~ "High Risk",
      pred_2024_food_insecure > quantile(predictions_2024, 0.5) ~ "Medium Risk",
      TRUE ~ "Low Risk"
    )
  ) %>%
  arrange(desc(pred_2024_food_insecure)) 


write.csv(
  results_2024,
  file = paste0("food_insecurity_predictions_", format(Sys.Date(), "%Y%m%d"), ".csv"),
  row.names = FALSE
)


library(ggplot2)
results_2024 %>%
  head(10) %>%
  ggplot(aes(x = reorder(county.x, -pred_2024_food_insecure), y = pred_2024_food_insecure)) +
  geom_col(fill = "firebrick") +
  labs(title = "Top 10 High-Risk Counties for 2024 Food Insecurity",
       x = "County",
       y = "Predicted Food Insecurity Rate") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

```{r}

library(caret)
library(Metrics)

test_predictions <- predict(xgb_optimized, newdata = X_test)
actual_values <- y_test 

metrics_table <- data.frame(
  RMSE = RMSE(test_predictions, actual_values),
  MAPE = mape(actual_values, test_predictions) * 100,
  MSE = mean((test_predictions - actual_values)^2),
  R2 = R2(test_predictions, actual_values)
)

print(metrics_table)
```

```{r}
library(caret)

perm_imp <- varImp(
  xgb_optimized,
  scale = TRUE,  
  type = "permutation",  
  numPermutations = 30  
)

ggplot(perm_imp, aes(x = reorder(rownames(perm_imp), Overall), y = Overall)) +
  geom_col(fill = "steelblue") +
  coord_flip() +
  labs(x = "Features", y = "Importance (Permutation)", 
       title = "Permutation Importance") +
  theme_minimal()


perm_imp_plot <- ggplot(perm_imp, aes(x = reorder(rownames(perm_imp), Overall), y = Overall)) +
  geom_col(fill = "steelblue") +
  coord_flip() +
  labs(x = "Features", y = "Importance (Permutation)", 
       title = "Permutation Importance (XGBoost Experiment 3)") +
  theme_minimal()

ggsave(
  filename = "permutation_importance.png",
  plot = perm_imp_plot,
  device = "png",
  width = 8,         
  height = 6,         
  units = "in",       
  dpi = 300,          
  bg = "white"        
)
```

## XGBoost 3: {.tabset}

This XGBoost model will attempt to do four things:
* Make sure the lag variables are actually backward-looking by adjusting how they are set. 
* Address overfitting by increasing regularization 
* increase early stopping. 
* Lastly, add in more interaction terms.

### Imputation Step:

```{r}
library(tidyverse)
library(mice)  # For advanced imputation

data <- read.csv("C:\\Users\\jashb\\OneDrive\\Documents\\Masters Data Science\\Spring 2025\\DATA 698\\Masters Project\\final_data.csv")

# This sapply function runs through the data and calculates the missing percentage across all columns
missing_pct <- sapply(data, function(x) mean(is.na(x)) * 100)

# 2. Rules I set (arbitrary) to decide what columns to keep and impute and which ones to drop
cols_to_impute <- names(missing_pct[missing_pct <= 25 & missing_pct > 0])
cols_to_drop <- names(missing_pct[missing_pct > 25])

# 3. Drop columns with 25% or more missingness
data_clean <- data %>% 
  select(-all_of(cols_to_drop))

# 4.
# Numeric columns: median imputation
num_cols <- data_clean %>% 
  select(where(is.numeric)) %>% 
  names() %>% 
  intersect(cols_to_impute)

data_clean <- data_clean %>%
  mutate(across(all_of(num_cols), ~ifelse(is.na(.), median(., na.rm = TRUE), .)))

# Categorical Columns: mode imputation
cat_cols <- data_clean %>% 
  select(where(is.character) | where(is.factor)) %>% 
  names() %>% 
  intersect(cols_to_impute)

get_mode <- function(x) {
  ux <- unique(x)
  ux[which.max(tabulate(match(x, ux)))]
}

data_clean <- data_clean %>%
  mutate(across(all_of(cat_cols), ~ifelse(is.na(.), get_mode(.), .)))

# 5. Drop rows with >25% missingness in remaining columns
row_missing_pct <- apply(data_clean, 1, function(x) mean(is.na(x)) * 100)
data_final <- data_clean[row_missing_pct <= 25, ]

```

### Combination variable creation
```{r}

df <- data_final %>%
  arrange(fips, year) %>% 
  group_by(fips) %>%
  mutate(
    food_insecure_lag1 = lag(percent_food_insecure, 1), 
    food_insecure_lag2 = lag(percent_food_insecure, 2)   
  ) %>%
  select(-food_environment_index) %>% 
  ungroup()


df <- df %>%
  mutate(rural_urban = as.factor(rural_urban),
         rural_urban = as.numeric(rural_urban),
    economic_stress = (
      percent_unemployed + 
      percent_children_in_poverty + 
      percent_severe_housing_problems
    ) / 3)
```



```{r}
train <- df %>% filter(year < 2024)
test <- df %>% filter(year == 2024)

X_train <- train %>% select(-c(year, fips, county.x, percent_food_insecure, state.x))
y_train <- train$percent_food_insecure

X_test <- test %>% select(-c(year, fips, county.x, percent_food_insecure, state.x))
y_test <- test$percent_food_insecure
```



```{r warning=FALSE}

ctrl_fast <- trainControl(
  method = "cv",
  number = 5,  # Reduce from 10 folds
  verboseIter = TRUE,
  allowParallel = TRUE  
)

# Focused tuning grid
xgb_grid_fast <- expand.grid(
  nrounds = c(100, 150),          # Reduced amount of options for nrounds
  max_depth = c(3, 4),            # drop down from 6 and 8 tree depth
  eta = c(0.01, 0.05),            # dropped down from 3 set options to 2
  gamma = c(0,1),                     # 0-1 to add regularization to help overfitting
  colsample_bytree = 0.8,         
  min_child_weight = 2,          # Increased from 1 to help prevent overfitting
  subsample = 0.8                # Fixed
)


library(doParallel)
cl <- makePSOCKcluster(4) 
registerDoParallel(cl)

xgb_fast <- train(
  x = X_train,
  y = y_train,
  method = "xgbTree",
  trControl = ctrl_fast,
  tuneGrid = xgb_grid_fast,
  verbosity = 0,                 
  metric = "RMSE"
)

stopCluster(cl)


print(xgb_fast)
plot(xgb_fast)
```

```{r}

library(doParallel)
library(Metrics)
cl <- makePSOCKcluster(4)  
registerDoParallel(cl)

# Reduced tuning grid with most impactful parameters
ctrl_fast <- trainControl(
  method = "cv",
  number = 5,  # Reduced from 10 folds
  verboseIter = TRUE,
  allowParallel = TRUE,  
  savePredictions = "final"
)


xgb_grid_fast <- expand.grid(
  nrounds = c(100, 150, 200, 300),
  max_depth = c(4, 6, 8), # Back to 4,6,8 because 3,4 RMSE was not great
  eta = c(0.05, 0.1, 0.15),
  gamma = c(0,1),
  colsample_bytree = 0.8,
  min_child_weight = 2,
  subsample = 0.8
)


xgb_optimized <- train(
  x = X_train,
  y = y_train,
  method = "xgbTree",
  trControl = ctrl_fast,
  tuneGrid = xgb_grid_fast,
  verbosity = 0,
  metric = "RMSE"
)

stopCluster(cl)


print(xgb_optimized)
plot(xgb_optimized)


best_params <- xgb_optimized$bestTune

X_2024 <- df %>% 
  filter(year == 2024) %>%
  select(-c(year, fips, county.x, percent_food_insecure)) %>%
  mutate(
    rural_urban = as.numeric(factor(rural_urban))
  )

predictions_2024 <- predict(xgb_optimized, newdata = X_2024)


results_2024 <- df %>%
  filter(year == 2024) %>%
  select(fips, county.x, percent_food_insecure) %>%  
  mutate(
    pred_2024_food_insecure = predictions_2024,
    predicted_change = pred_2024_food_insecure - percent_food_insecure,
    risk_category = case_when(
      pred_2024_food_insecure > quantile(predictions_2024, 0.75) ~ "High Risk",
      pred_2024_food_insecure > quantile(predictions_2024, 0.5) ~ "Medium Risk",
      TRUE ~ "Low Risk"
    )
  ) %>%
  arrange(desc(pred_2024_food_insecure))


write.csv(
  results_2024,
  file = paste0("food_insecurity_predictions_", format(Sys.Date(), "%Y%m%d"), ".csv"),
  row.names = FALSE
)


library(ggplot2)
results_2024 %>%
  head(10) %>%
  ggplot(aes(x = reorder(county.x, -pred_2024_food_insecure), y = pred_2024_food_insecure)) +
  geom_col(fill = "firebrick") +
  labs(title = "Top 10 High-Risk Counties for 2024 Food Insecurity",
       x = "County",
       y = "Predicted Food Insecurity Rate") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```
* The final values used for the model were nrounds = 300, max_depth = 4, eta = 0.05, gamma = 0, colsample_bytree = 0.8, min_child_weight = 2 and subsample = 0.8.

```{r}
library(caret)
library(Metrics)

test_predictions <- predict(xgb_optimized, newdata = X_test)
actual_values <- y_test 

metrics_table <- data.frame(
  RMSE = RMSE(test_predictions, actual_values),
  MAPE = mape(actual_values, test_predictions) * 100,
  MSE = mean((test_predictions - actual_values)^2),
  R2 = R2(test_predictions, actual_values)
)

print(metrics_table)
```


### Geospacial graphing for the best performing XGBoost model:

```{r}
# SF and Tigris are used to call in geospacial data for mapping purposes
library(sf)
library(tigris)

# Get counties in native projection (no transformation)
ny_counties <- counties(state = "NY", cb = TRUE, year = 2021, class = "sf") %>% 
  select(fips = GEOID, geometry)

# Filtering out the NY Total Row
results_2024_clean <- results_2024 %>%
  filter(fips != 36000) %>%
  mutate(fips = as.character(fips))

# Merge and plot the predictions with sf and tigris mapping data
ny_counties %>%
  left_join(results_2024_clean, by = "fips") %>%
  drop_na(pred_2024_food_insecure) %>%
  ggplot() +
  geom_sf(aes(fill = pred_2024_food_insecure), color = NA) +
  scale_fill_viridis_c("Food Insecurity (%)", option = "inferno", direction = -1) +
  labs(title = "New York State 2025 Predicted Food Insecurity by County") +
  theme_void()

ny_map <- ny_counties %>%
  left_join(results_2024_clean, by = "fips") %>%
  drop_na(pred_2024_food_insecure) %>%
  ggplot() +
  geom_sf(aes(fill = pred_2024_food_insecure), color = NA) +
  scale_fill_viridis_c(
    "Food Insecurity (%)", 
    option = "inferno", 
    direction = -1,
    limits = c(0, max(results_2024_clean$pred_2024_food_insecure))
  ) +
  labs(
    title = "New York State 2024 Predicted Food Insecurity by County",
    caption = "Data: County Health Rankings"
  ) +
  theme_void() +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold", size = 14),
    legend.position = "right",
    legend.title = element_text(size = 10)
  )


ggsave(
  filename = "ny_food_insecurity_2025.png",
  plot = ny_map,
  device = "png",
  width = 10,   
  height = 8,       
  units = "in", 
  dpi = 300,        
  bg = "white"      
)
```

### Variable Importance for the best perfoming model:


```{r}
library(caret)

perm_imp <- varImp(
  xgb_optimized,
  scale = TRUE,  
  type = "permutation", 
  numPermutations = 30  
)

ggplot(perm_imp, aes(x = reorder(rownames(perm_imp), Overall), y = Overall)) +
  geom_col(fill = "steelblue") +
  coord_flip() +
  labs(x = "Features", y = "Importance (Permutation)", 
       title = "Permutation Importance") +
  theme_minimal()


perm_imp_plot <- ggplot(perm_imp, aes(x = reorder(rownames(perm_imp), Overall), y = Overall)) +
  geom_col(fill = "steelblue") +
  coord_flip() +
  labs(x = "Features", y = "Importance (Permutation)", 
       title = "Permutation Importance (XGBoost Experiment 3)") +
  theme_minimal()

ggsave(
  filename = "permutation_importance.png",
  plot = perm_imp_plot,
  device = "png",
  width = 8,         
  height = 6,         
  units = "in",       
  dpi = 300,          
  bg = "white"        
)
```

